{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch_Practice.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMGMznHlyTkvsXDEX8v/hEI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VK5MSomELKSf"},"source":["## Pytorch"]},{"cell_type":"markdown","metadata":{"id":"FB4CcUvULMW0"},"source":["1. Dataset, DataLoader 로 데이터 전처리 모듈 선언\n","2. nn.Module 을 상속해 모델 선언\n","3. GPU 옮기기 및 하이퍼파라미터 정의\n","4. 훈련코드 구성\n","    - 모델이 gpu에 있으면 데이터도 gpu 에 있어야함 (마찬가지로 to(device) 로)\n","    - GPU에 옮길때는 할당을 해주어야 함\n","        - X = X.to(device)\n","5. 결과 확인"]},{"cell_type":"markdown","metadata":{"id":"i4kCbROpLXWt"},"source":["## Practice"]},{"cell_type":"code","metadata":{"id":"8WtZluRPK_2o","executionInfo":{"status":"ok","timestamp":1622773815533,"user_tz":-540,"elapsed":227,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}}},"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda\n","\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True) \n","test_dataloader = DataLoader(test_data, batch_size=64)\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","            nn.ReLU()\n","        )\n","        #self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","        #return self.softmax(logits)\n","\n","model = NeuralNetwork()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ySJAAxAL2XR","executionInfo":{"status":"ok","timestamp":1622773816305,"user_tz":-540,"elapsed":3,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}}},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model = model.to(device)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"DH1DSGXBLFDX","executionInfo":{"status":"ok","timestamp":1622773816975,"user_tz":-540,"elapsed":244,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}}},"source":["def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Compute prediction and loss\n","        pred = model(X.to(device))\n","        loss = loss_fn(pred, y.to(device))\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","\n","def test_loop(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            pred = model(X.to(device))\n","            test_loss += loss_fn(pred, y.to(device)).item()\n","            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n","\n","    test_loss /= size\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n","    return correct"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLvJT2zlLcKG","executionInfo":{"status":"ok","timestamp":1622773817721,"user_tz":-540,"elapsed":3,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}}},"source":["learning_rate = 1e-3\n","batch_size = 64\n","epochs = 20"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7QmKJLpLlY4","executionInfo":{"status":"ok","timestamp":1622773919136,"user_tz":-540,"elapsed":101179,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}},"outputId":"7619c1d5-f6b4-4978-b39c-c1a8ccf622a5"},"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","best_correct = -float('inf')\n","best_epoch = 0\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train_loop(train_dataloader, model, loss_fn, optimizer)\n","    test_correct = test_loop(test_dataloader, model, loss_fn)\n","    if test_correct > best_correct:\n","        ## 1. 모델을 save\n","        best_epoch = t\n","\n","    ## Prevent overfitting so we do early stopping\n","    if t - best_epoch > interval:\n","        break\n","\n","print(\"Done!\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Epoch 1\n","-------------------------------\n","loss: 2.304649  [    0/60000]\n","loss: 2.294202  [ 6400/60000]\n","loss: 2.287575  [12800/60000]\n","loss: 2.276610  [19200/60000]\n","loss: 2.266536  [25600/60000]\n","loss: 2.282603  [32000/60000]\n","loss: 2.253023  [38400/60000]\n","loss: 2.243524  [44800/60000]\n","loss: 2.225875  [51200/60000]\n","loss: 2.227046  [57600/60000]\n","Test Error: \n"," Accuracy: 40.1%, Avg loss: 0.034691 \n","\n","Epoch 2\n","-------------------------------\n","loss: 2.183432  [    0/60000]\n","loss: 2.190336  [ 6400/60000]\n","loss: 2.171289  [12800/60000]\n","loss: 2.188579  [19200/60000]\n","loss: 2.154699  [25600/60000]\n","loss: 2.117106  [32000/60000]\n","loss: 2.145584  [38400/60000]\n","loss: 2.096020  [44800/60000]\n","loss: 2.087687  [51200/60000]\n","loss: 1.990192  [57600/60000]\n","Test Error: \n"," Accuracy: 50.5%, Avg loss: 0.032366 \n","\n","Epoch 3\n","-------------------------------\n","loss: 2.046099  [    0/60000]\n","loss: 2.027740  [ 6400/60000]\n","loss: 2.083007  [12800/60000]\n","loss: 1.941570  [19200/60000]\n","loss: 2.024612  [25600/60000]\n","loss: 1.948576  [32000/60000]\n","loss: 1.964130  [38400/60000]\n","loss: 1.897874  [44800/60000]\n","loss: 1.826397  [51200/60000]\n","loss: 1.875662  [57600/60000]\n","Test Error: \n"," Accuracy: 54.4%, Avg loss: 0.028999 \n","\n","Epoch 4\n","-------------------------------\n","loss: 2.032394  [    0/60000]\n","loss: 1.747598  [ 6400/60000]\n","loss: 1.657018  [12800/60000]\n","loss: 1.822520  [19200/60000]\n","loss: 1.753494  [25600/60000]\n","loss: 1.499132  [32000/60000]\n","loss: 1.665546  [38400/60000]\n","loss: 1.687829  [44800/60000]\n","loss: 1.689318  [51200/60000]\n","loss: 1.840560  [57600/60000]\n","Test Error: \n"," Accuracy: 55.8%, Avg loss: 0.025818 \n","\n","Epoch 5\n","-------------------------------\n","loss: 1.596182  [    0/60000]\n","loss: 1.830855  [ 6400/60000]\n","loss: 1.729562  [12800/60000]\n","loss: 1.623798  [19200/60000]\n","loss: 1.685459  [25600/60000]\n","loss: 1.442425  [32000/60000]\n","loss: 1.695879  [38400/60000]\n","loss: 1.501068  [44800/60000]\n","loss: 1.429014  [51200/60000]\n","loss: 1.420713  [57600/60000]\n","Test Error: \n"," Accuracy: 56.0%, Avg loss: 0.023521 \n","\n","Epoch 6\n","-------------------------------\n","loss: 1.423376  [    0/60000]\n","loss: 1.508527  [ 6400/60000]\n","loss: 1.427442  [12800/60000]\n","loss: 1.458740  [19200/60000]\n","loss: 1.268769  [25600/60000]\n","loss: 1.437401  [32000/60000]\n","loss: 1.330485  [38400/60000]\n","loss: 1.655277  [44800/60000]\n","loss: 1.306177  [51200/60000]\n","loss: 1.489652  [57600/60000]\n","Test Error: \n"," Accuracy: 56.8%, Avg loss: 0.021970 \n","\n","Epoch 7\n","-------------------------------\n","loss: 1.388112  [    0/60000]\n","loss: 1.244895  [ 6400/60000]\n","loss: 1.512527  [12800/60000]\n","loss: 1.491657  [19200/60000]\n","loss: 1.504251  [25600/60000]\n","loss: 1.522442  [32000/60000]\n","loss: 1.329901  [38400/60000]\n","loss: 1.294142  [44800/60000]\n","loss: 1.105134  [51200/60000]\n","loss: 1.513962  [57600/60000]\n","Test Error: \n"," Accuracy: 58.5%, Avg loss: 0.020877 \n","\n","Epoch 8\n","-------------------------------\n","loss: 1.288389  [    0/60000]\n","loss: 1.329700  [ 6400/60000]\n","loss: 1.369266  [12800/60000]\n","loss: 1.329581  [19200/60000]\n","loss: 1.300841  [25600/60000]\n","loss: 1.339325  [32000/60000]\n","loss: 1.283793  [38400/60000]\n","loss: 1.426302  [44800/60000]\n","loss: 1.165843  [51200/60000]\n","loss: 0.937542  [57600/60000]\n","Test Error: \n"," Accuracy: 59.0%, Avg loss: 0.020082 \n","\n","Epoch 9\n","-------------------------------\n","loss: 1.181154  [    0/60000]\n","loss: 1.301987  [ 6400/60000]\n","loss: 1.128061  [12800/60000]\n","loss: 1.231377  [19200/60000]\n","loss: 1.022205  [25600/60000]\n","loss: 1.201856  [32000/60000]\n","loss: 1.172991  [38400/60000]\n","loss: 1.320432  [44800/60000]\n","loss: 1.179830  [51200/60000]\n","loss: 1.065904  [57600/60000]\n","Test Error: \n"," Accuracy: 60.0%, Avg loss: 0.019473 \n","\n","Epoch 10\n","-------------------------------\n","loss: 1.188353  [    0/60000]\n","loss: 1.367831  [ 6400/60000]\n","loss: 1.194810  [12800/60000]\n","loss: 1.145169  [19200/60000]\n","loss: 1.397818  [25600/60000]\n","loss: 1.144397  [32000/60000]\n","loss: 1.427206  [38400/60000]\n","loss: 1.096111  [44800/60000]\n","loss: 1.212396  [51200/60000]\n","loss: 1.153089  [57600/60000]\n","Test Error: \n"," Accuracy: 60.9%, Avg loss: 0.018979 \n","\n","Epoch 11\n","-------------------------------\n","loss: 1.230978  [    0/60000]\n","loss: 1.226468  [ 6400/60000]\n","loss: 1.272041  [12800/60000]\n","loss: 0.967084  [19200/60000]\n","loss: 1.146704  [25600/60000]\n","loss: 1.248668  [32000/60000]\n","loss: 1.022494  [38400/60000]\n","loss: 1.238889  [44800/60000]\n","loss: 1.135836  [51200/60000]\n","loss: 1.211426  [57600/60000]\n","Test Error: \n"," Accuracy: 62.1%, Avg loss: 0.018556 \n","\n","Epoch 12\n","-------------------------------\n","loss: 1.198044  [    0/60000]\n","loss: 1.042026  [ 6400/60000]\n","loss: 1.260632  [12800/60000]\n","loss: 0.959438  [19200/60000]\n","loss: 1.147471  [25600/60000]\n","loss: 1.246031  [32000/60000]\n","loss: 1.167385  [38400/60000]\n","loss: 1.275768  [44800/60000]\n","loss: 1.038063  [51200/60000]\n","loss: 1.277888  [57600/60000]\n","Test Error: \n"," Accuracy: 62.9%, Avg loss: 0.018191 \n","\n","Epoch 13\n","-------------------------------\n","loss: 0.848626  [    0/60000]\n","loss: 1.117468  [ 6400/60000]\n","loss: 0.961382  [12800/60000]\n","loss: 1.119735  [19200/60000]\n","loss: 1.204938  [25600/60000]\n","loss: 0.998792  [32000/60000]\n","loss: 1.111327  [38400/60000]\n","loss: 1.108294  [44800/60000]\n","loss: 1.235190  [51200/60000]\n","loss: 1.136024  [57600/60000]\n","Test Error: \n"," Accuracy: 64.1%, Avg loss: 0.017872 \n","\n","Epoch 14\n","-------------------------------\n","loss: 1.027246  [    0/60000]\n","loss: 1.256904  [ 6400/60000]\n","loss: 1.334050  [12800/60000]\n","loss: 0.938224  [19200/60000]\n","loss: 1.199579  [25600/60000]\n","loss: 1.214026  [32000/60000]\n","loss: 1.276261  [38400/60000]\n","loss: 1.151736  [44800/60000]\n","loss: 1.183632  [51200/60000]\n","loss: 1.306682  [57600/60000]\n","Test Error: \n"," Accuracy: 64.4%, Avg loss: 0.017583 \n","\n","Epoch 15\n","-------------------------------\n","loss: 1.001718  [    0/60000]\n","loss: 1.227470  [ 6400/60000]\n","loss: 1.002671  [12800/60000]\n","loss: 1.174996  [19200/60000]\n","loss: 1.196659  [25600/60000]\n","loss: 1.300369  [32000/60000]\n","loss: 1.174352  [38400/60000]\n","loss: 1.029916  [44800/60000]\n","loss: 0.945528  [51200/60000]\n","loss: 1.080957  [57600/60000]\n","Test Error: \n"," Accuracy: 65.4%, Avg loss: 0.017331 \n","\n","Epoch 16\n","-------------------------------\n","loss: 0.920209  [    0/60000]\n","loss: 0.946130  [ 6400/60000]\n","loss: 1.121162  [12800/60000]\n","loss: 0.969380  [19200/60000]\n","loss: 1.205139  [25600/60000]\n","loss: 0.923243  [32000/60000]\n","loss: 1.303676  [38400/60000]\n","loss: 0.995675  [44800/60000]\n","loss: 1.202334  [51200/60000]\n","loss: 1.186653  [57600/60000]\n","Test Error: \n"," Accuracy: 65.7%, Avg loss: 0.017099 \n","\n","Epoch 17\n","-------------------------------\n","loss: 1.163077  [    0/60000]\n","loss: 1.111488  [ 6400/60000]\n","loss: 1.138715  [12800/60000]\n","loss: 1.047209  [19200/60000]\n","loss: 1.021049  [25600/60000]\n","loss: 1.144059  [32000/60000]\n","loss: 1.296285  [38400/60000]\n","loss: 1.324944  [44800/60000]\n","loss: 0.932757  [51200/60000]\n","loss: 1.102735  [57600/60000]\n","Test Error: \n"," Accuracy: 66.1%, Avg loss: 0.016878 \n","\n","Epoch 18\n","-------------------------------\n","loss: 1.281086  [    0/60000]\n","loss: 1.052559  [ 6400/60000]\n","loss: 1.114050  [12800/60000]\n","loss: 0.955789  [19200/60000]\n","loss: 1.351170  [25600/60000]\n","loss: 0.868593  [32000/60000]\n","loss: 1.151154  [38400/60000]\n","loss: 1.374509  [44800/60000]\n","loss: 1.224471  [51200/60000]\n","loss: 1.061981  [57600/60000]\n","Test Error: \n"," Accuracy: 66.7%, Avg loss: 0.016680 \n","\n","Epoch 19\n","-------------------------------\n","loss: 0.950307  [    0/60000]\n","loss: 0.994659  [ 6400/60000]\n","loss: 1.194863  [12800/60000]\n","loss: 0.906252  [19200/60000]\n","loss: 0.901726  [25600/60000]\n","loss: 0.898124  [32000/60000]\n","loss: 1.096455  [38400/60000]\n","loss: 1.000919  [44800/60000]\n","loss: 0.949474  [51200/60000]\n","loss: 1.031092  [57600/60000]\n","Test Error: \n"," Accuracy: 67.2%, Avg loss: 0.016495 \n","\n","Epoch 20\n","-------------------------------\n","loss: 1.255775  [    0/60000]\n","loss: 0.911407  [ 6400/60000]\n","loss: 0.928653  [12800/60000]\n","loss: 0.949668  [19200/60000]\n","loss: 1.086413  [25600/60000]\n","loss: 0.875320  [32000/60000]\n","loss: 1.084418  [38400/60000]\n","loss: 0.798431  [44800/60000]\n","loss: 0.907457  [51200/60000]\n","loss: 0.823901  [57600/60000]\n","Test Error: \n"," Accuracy: 67.3%, Avg loss: 0.016327 \n","\n","Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pTzmbT2Y6HL9"},"source":["### Model improvements?\n","\n","1. Transfer learning (조금 더 좋은 출발조건)\n","2. Data augmentation (rotation, tranlation, flipping)\n","3. CNN\n","4. Hyperparameter fine-tuning\n"]},{"cell_type":"code","metadata":{"id":"jFhFLpAoMfJ4"},"source":[""],"execution_count":null,"outputs":[]}]}