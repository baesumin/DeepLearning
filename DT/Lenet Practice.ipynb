{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lenet Practice.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNgyqhQeQNamBliXcJvlspW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f156f770cc0544f8ac370284326fb126":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_98b0164cdb324a4f8dd2b02dd73faf93","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7ad65b4e3a044008b2ba2f4084a1ef5e","IPY_MODEL_4e8095befc8f48c89022e29790d37724"]}},"98b0164cdb324a4f8dd2b02dd73faf93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ad65b4e3a044008b2ba2f4084a1ef5e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d0f8da79a3ea4f839844e674f1da53f0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9912422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9912422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_40c7bfd72f6843528cbfdc3b91a54ec5"}},"4e8095befc8f48c89022e29790d37724":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ac9e353d359c44fd92cddb02413861d2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9913344/? [01:31&lt;00:00, 108438.84it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d3b35e6ff0254f97a05ffc46604f69fa"}},"d0f8da79a3ea4f839844e674f1da53f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"40c7bfd72f6843528cbfdc3b91a54ec5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ac9e353d359c44fd92cddb02413861d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d3b35e6ff0254f97a05ffc46604f69fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ff44c6d5f9140af9d766571d01e95fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_07855417d9694264889e8ca51a8154c4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_af428d0e435647d491b8fee5c284cdbb","IPY_MODEL_4d577fc75720465ab05216246fd434dc"]}},"07855417d9694264889e8ca51a8154c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af428d0e435647d491b8fee5c284cdbb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2964316c88074472b7e19745bbe1a956","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a1968044ba87410fa8ee32912de9d798"}},"4d577fc75720465ab05216246fd434dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6354289b54564d32bb1eb7945eaf3547","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [00:00&lt;00:00, 47868.10it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3968475379284cfeb6e06a1dfa396527"}},"2964316c88074472b7e19745bbe1a956":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a1968044ba87410fa8ee32912de9d798":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6354289b54564d32bb1eb7945eaf3547":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3968475379284cfeb6e06a1dfa396527":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9927241b5c6c4ea3a35a1fef7f89fbcf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bc125076267142dd89d2693c6438f2e1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f1947aacb18143b89911f48aa1bb319e","IPY_MODEL_dfeb249caff54356b80bf4391716dd57"]}},"bc125076267142dd89d2693c6438f2e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1947aacb18143b89911f48aa1bb319e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ec6c8466252245458adf767a92f01b6f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1648877,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1648877,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7072fe6189e3411f95163b4d86fd438a"}},"dfeb249caff54356b80bf4391716dd57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bfe7f6e444dd4c2c804744c134fb2afa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1649664/? [01:29&lt;00:00, 18363.82it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f992b83209e44c4d8a7fc4d0d4c40373"}},"ec6c8466252245458adf767a92f01b6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7072fe6189e3411f95163b4d86fd438a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bfe7f6e444dd4c2c804744c134fb2afa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f992b83209e44c4d8a7fc4d0d4c40373":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ee94b1b7acb43e38320b9031f0f404c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cdbd381fc45a4c4dbd11df97fbf2a9d8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e296492adfeb4fa9904a71a2e16a11a7","IPY_MODEL_9cfc76f2b8994d4ea2c4fb2ae606fc99"]}},"cdbd381fc45a4c4dbd11df97fbf2a9d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e296492adfeb4fa9904a71a2e16a11a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d1e5b945b45e4128bb0e0583e81263ba","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4542,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4542,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d303634622ad4f9b87fd368637bd3cf5"}},"9cfc76f2b8994d4ea2c4fb2ae606fc99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_90b2868a51d0402f919dd30f429af7af","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5120/? [00:39&lt;00:00, 129.08it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_721ac86899e748c29e296dd4801f9012"}},"d1e5b945b45e4128bb0e0583e81263ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d303634622ad4f9b87fd368637bd3cf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"90b2868a51d0402f919dd30f429af7af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"721ac86899e748c29e296dd4801f9012":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"I5NFxJmzd8dA"},"source":["# MNIST classification with Lenet"]},{"cell_type":"markdown","metadata":{"id":"dQRf8xvCgRj_"},"source":["필요한 모든 라이브러리 import"]},{"cell_type":"code","metadata":{"id":"sb-O25W6nzTm","executionInfo":{"status":"ok","timestamp":1625186904661,"user_tz":-540,"elapsed":4663,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.utils.data as data\n","\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2oP0xif7d_5W"},"source":["## MNIST dataset load"]},{"cell_type":"markdown","metadata":{"id":"OgxULoT4oNnO"},"source":["1. torchvision.datasets 모듈에서 MNIST 훈련 데이터셋을 불러와 정규화를 위해 평균, 표준편차 구하기\n","2. \n","- 훈련 데이터셋의 transform 정의\n","- Random Rotation by degree 5\n","- padding 2를 먼저 붙이고 random crop\n","- 텐서화 (ToTensor)\n","- 평균, 표준편차로 정규화\n","\n","- 테스트 데이터셋의 transform 정의\n","- 텐서화\n","- 평균, 표준편차로 정규화\n","3. torch.utils.data.random_split 메소드를 이용해 90/10 비율로 train/val 데이터셋 구성\n","4. valid data의 transformation을 test_transformation으로 재정의\n","5. 배치 사이즈를 64로 한 train/val/test dataloader 구성\n"]},{"cell_type":"markdown","metadata":{"id":"V4VZGwBFeCTI"},"source":["torchvision.datasets 모듈에서 MNIST 훈련 데이터셋을 불러와 정규화를 위해 평균, 표준편차 구하기"]},{"cell_type":"code","metadata":{"id":"AfBrNaUAdxrK","colab":{"base_uri":"https://localhost:8080/","height":876,"referenced_widgets":["f156f770cc0544f8ac370284326fb126","98b0164cdb324a4f8dd2b02dd73faf93","7ad65b4e3a044008b2ba2f4084a1ef5e","4e8095befc8f48c89022e29790d37724","d0f8da79a3ea4f839844e674f1da53f0","40c7bfd72f6843528cbfdc3b91a54ec5","ac9e353d359c44fd92cddb02413861d2","d3b35e6ff0254f97a05ffc46604f69fa","6ff44c6d5f9140af9d766571d01e95fd","07855417d9694264889e8ca51a8154c4","af428d0e435647d491b8fee5c284cdbb","4d577fc75720465ab05216246fd434dc","2964316c88074472b7e19745bbe1a956","a1968044ba87410fa8ee32912de9d798","6354289b54564d32bb1eb7945eaf3547","3968475379284cfeb6e06a1dfa396527","9927241b5c6c4ea3a35a1fef7f89fbcf","bc125076267142dd89d2693c6438f2e1","f1947aacb18143b89911f48aa1bb319e","dfeb249caff54356b80bf4391716dd57","ec6c8466252245458adf767a92f01b6f","7072fe6189e3411f95163b4d86fd438a","bfe7f6e444dd4c2c804744c134fb2afa","f992b83209e44c4d8a7fc4d0d4c40373","0ee94b1b7acb43e38320b9031f0f404c","cdbd381fc45a4c4dbd11df97fbf2a9d8","e296492adfeb4fa9904a71a2e16a11a7","9cfc76f2b8994d4ea2c4fb2ae606fc99","d1e5b945b45e4128bb0e0583e81263ba","d303634622ad4f9b87fd368637bd3cf5","90b2868a51d0402f919dd30f429af7af","721ac86899e748c29e296dd4801f9012"]},"executionInfo":{"status":"ok","timestamp":1625187028681,"user_tz":-540,"elapsed":3788,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}},"outputId":"1dc4325f-6bdf-4158-81d2-24cf23dbc629"},"source":["train_data = datasets.MNIST(root='./data', train=True, download=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 503: Service Unavailable\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f156f770cc0544f8ac370284326fb126","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ff44c6d5f9140af9d766571d01e95fd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 503: Service Unavailable\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9927241b5c6c4ea3a35a1fef7f89fbcf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 503: Service Unavailable\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ee94b1b7acb43e38320b9031f0f404c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["Dataset MNIST\n","    Number of datapoints: 60000\n","    Root location: ./data\n","    Split: Train"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Q_ziF_3snfL","executionInfo":{"status":"ok","timestamp":1625187169752,"user_tz":-540,"elapsed":273,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}},"outputId":"3f960438-4709-410e-d03e-d439966a6ec9"},"source":["mean = train_data.data.float().mean() / 255\n","std = train_data.data.float().std() / 255\n","print(f'Mean {mean:.3f}, Std {std:.3f}')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mean 0.131, Std 0.308\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9a76Bv29eKVm"},"source":["훈련 데이터셋의 transform 정의\n","- Random Rotation by degree 5\n","- padding 2를 먼저 붙이고 random crop\n","- 텐서화 (ToTensor)\n","- 평균, 표준편차로 정규화\n","\n","테스트 데이터셋의 transform 정의\n","- 텐서화\n","- 평균, 표준편차로 정규화\n"]},{"cell_type":"code","metadata":{"id":"Lc86v5L0eQO1","executionInfo":{"status":"ok","timestamp":1625187623751,"user_tz":-540,"elapsed":250,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}}},"source":["train_transform = transforms.Compose([\n","                            transforms.RandomRotation(5, fill=0),\n","                            transforms.RandomCrop(size=28, padding=2),\n","                            transforms.ToTensor(), \n","                            transforms.Normalize(mean=[mean], std=[std])\n","                                    ])\n","test_transform = transforms.Compose([\n","                            transforms.ToTensor(),\n","                            transforms.Normalize(mean=[mean], std=[std])\n","                                    ])"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fdWP5j6wueXm"},"source":["정의한 transformation 기반으로 데이터셋 로드"]},{"cell_type":"code","metadata":{"id":"imfHSbsJuiFf","executionInfo":{"status":"ok","timestamp":1625187628157,"user_tz":-540,"elapsed":325,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}}},"source":["train_data = datasets.MNIST(root='./data', train=True, download=True, transform=train_transform)\n","test_data = datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YONTU2jIe99K"},"source":["torch.utils.data.random_split 메소드를 이용해 90/10 비율로 train/val 데이터셋 구성"]},{"cell_type":"code","metadata":{"id":"SNneAfIPfCrj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625187721294,"user_tz":-540,"elapsed":258,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}},"outputId":"0f060dca-1b50-40ef-98cd-06c4662072b3"},"source":["ratio = 0.9\n","num_trains = int(len(train_data)*ratio)\n","num_vals = len(train_data) - num_trains\n","\n","train_data, val_data = data.random_split(train_data, [num_trains, num_vals])\n","print(f'Length of Train Dataset: {len(train_data)}')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Length of Train Dataset: 54000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7oh3NuwAfiQe"},"source":["Validation 데이터셋의 transform 을 test_transform 으로 변환"]},{"cell_type":"code","metadata":{"id":"7K6JoiOOfl8u","executionInfo":{"status":"ok","timestamp":1625187747351,"user_tz":-540,"elapsed":252,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}}},"source":["val_data.dataset.transform = test_transform"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a1qcpF_Ufm0M"},"source":["train/val/test 데이터셋의 크기 출력"]},{"cell_type":"code","metadata":{"id":"FvuOvOcifqE8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625187777698,"user_tz":-540,"elapsed":312,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}},"outputId":"8db232a7-91a7-49ce-b589-a83c763e17c4"},"source":["print(f'Length of Train Dataset: {len(train_data)}')\n","print(f'Length of Val Dataset: {len(val_data)}')\n","print(f'Length of Test Dataset: {len(test_data)}')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Length of Train Dataset: 54000\n","Length of Val Dataset: 6000\n","Length of Test Dataset: 10000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CEse7z62fqsk"},"source":["배치 사이즈를 64로 하여 dataloader 구성"]},{"cell_type":"code","metadata":{"id":"txbMEnHuftQr","executionInfo":{"status":"ok","timestamp":1625187850821,"user_tz":-540,"elapsed":248,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}}},"source":["batch_size = 64\n","\n","train_iterator = data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","val_iterator = data.DataLoader(val_data, batch_size=batch_size)\n","test_iterator = data.DataLoader(test_data, batch_size=batch_size)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fSzGXxd-vyc6"},"source":["Generator - Yield"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j7rxOUgJvqJn","executionInfo":{"status":"ok","timestamp":1625187880584,"user_tz":-540,"elapsed":261,"user":{"displayName":"yongjun Hong","photoUrl":"","userId":"12232445946572661990"}},"outputId":"84e6c2e6-253d-4412-f2ce-3287b772af61"},"source":["X, y = next(iter(train_iterator))\n","print(X.shape, y.shape)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["torch.Size([64, 1, 28, 28]) torch.Size([64])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ua-XeZIvfvMs"},"source":["## Define Model"]},{"cell_type":"markdown","metadata":{"id":"WFGyf315gIOC"},"source":["### Convolution"]},{"cell_type":"markdown","metadata":{"id":"63IEXTBOgMRx"},"source":["The LeNet architectures, and almost every modern neural network computer vision architecture makes use of convolutional neural network (CNN) layers. \n","\n","So, what is a CNN layer? Each convolutional layer has a number of *filters*, also commonly referred to as *kernels*. A filter is a (usually) square matrix that slides across the pixels in an image from left-to-right, top-to-bottom. At each \"step\", the filter performs a [convolution](https://en.wikipedia.org/wiki/Convolution) operation on the image. The output of the convolutional layer is the result of these convolutions after the filter's final \"step\". \n","\n","**Note:** in machine learning frameworks there aren't actually \"steps\", the result for every filter location is calculated at the same time, in parallel. This is a lot faster than actually stepping through the image, but thinking about it in terms of steps makes everything easier to visualize.\n","\n","Let's have a look at a single 2x2 filter passing over an image. We'll pretend the image is 10x10 pixels in this example.\n","\n","![](https://github.com/bentrevett/pytorch-image-classification/blob/master/assets/filter-mnist.png?raw=1)\n","\n","The filter (red) slides over the pixels of the image, stepping one pixel at a time. The size of the steps is called the *stride*, and we use a stride of one in this implementation, which means the filter moves one pixel at a time horizontally and moves one pixel down once it reaches the end of a row. The result of the convolution operation (green) is a pixel in the filtered image. All of these convolutions produce a new, filtered image.\n","\n","Notice how the image coming out of the CNN layer is smaller than the image coming into the CNN. This is because the 2x2 filter has only nine steps horizontally and vertically. If we wanted to keep the output image the same size as the input image we could add padding - usually black pixels - around our image. \n","\n","When we have no padding and a step size of one, the size of the output image is: \n","\n","$$\\text{height}_{\\text{out}} = \\text{height}_{\\text{in}} - \\text{filter}_{\\text{height}} + 1$$\n","\n","$$\\text{width}_{\\text{out}} = \\text{width}_{\\text{in}} - \\text{filter}_{\\text{width}} + 1$$\n","\n","How do we calculate the values of the output pixels using the filter? It's simply a multiply and add! Each of the input image pixels covered by a filter is multiplied by the filter's weight over that pixel. All of these products are then summed together to get the value of the pixel in the output image.\n","\n","![](https://github.com/bentrevett/pytorch-image-classification/blob/master/assets/single-filter.png?raw=1)\n","\n","The same weights are used by the filter over the whole image. The weights do not change depending on the filters location within the image. One nice thing about this is that that the filters (and the convolutional layers themselves) are *translation invariant*, that means it doesn't matter where a feature (curve, edge, line) appears in an image, the convolutional layer will find all occurences of it. \n","\n","The weights for the filters, much like the weights of the linear layers in multilayer perceptrons, are learned via gradient descent and backpropagation.\n","\n","Why are convolutional neural networks structured in this way? Filters applied across an image in this way can be used to detect patterns such as horizontal and vertical lines within an image. These patterns can be thought of as features of the image, which our CNN extracts. These extracted features can then be combined in further layers of the neural network with other extracted features and together create higher level features, e.g. a certain position and orientation of two lines make a cross, which can indicate the centre of a handwritten 4.\n","\n","CNNs are also inspired by classic computer vision techniques, like [Sobel filters](https://en.wikipedia.org/wiki/Sobel_operator). Let's try manually choosing weights of a 3x3 filter to make Sobel filters and apply them to some of the MNIST digits to see what type of things our CNN layers can learn.\n","\n","The `plot_filter` function takes in a batch of images and a two-dimensional filter and plots the output of that filter applied to all of the images."]},{"cell_type":"code","metadata":{"id":"1A47jOVifxH1"},"source":["def plot_filter(images, filter):\n","\n","    images = images = torch.cat([i.unsqueeze(0) for i in images], dim = 0).cpu()\n","    filter = torch.FloatTensor(filter).unsqueeze(0).unsqueeze(0).cpu()\n","    \n","    n_images = images.shape[0]\n","\n","    filtered_images = F.conv2d(images, filter)\n","\n","    fig = plt.figure(figsize = (20, 5))\n","    \n","    for i in range(n_images):\n","\n","        ax = fig.add_subplot(2, n_images, i+1)\n","        ax.imshow(images[i].squeeze(0), cmap = 'bone')\n","        ax.set_title('Original')\n","        ax.axis('off')\n","\n","        image = filtered_images[i].squeeze(0)\n","\n","        ax = fig.add_subplot(2, n_images, n_images+i+1)\n","        ax.imshow(image, cmap='bone')\n","        ax.set_title(f'Filtered')\n","        ax.axis('off');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M08LRHJjgYJv"},"source":["We'll then get a batch of images to test our handwritten Sobel filters on. We get the images from the test set as they're easier to examine without the transforms applied to them."]},{"cell_type":"code","metadata":{"id":"K3RB8u_xgZnK"},"source":["N_IMAGES = 5\n","\n","images = [image for image, label in [test_data[i] for i in range(N_IMAGES)]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ndO4LjLugeP6"},"source":["The first filter is for detecting horizontal lines.\n","\n","We can see on the filtered images that the highest values (the whitest pixels) of the filtered image are where there is a horizontal line that is black on top and white below, e.g. the top of the 7 digit. The lowest values (the blackest pixels) of the filtered image are where there is a horizontal line that goes from white to black, e.g. the bottoms of all of the digits."]},{"cell_type":"code","metadata":{"id":"_4x2W2fngf2P"},"source":["horizontal_filter = [[-1, -2, -1],\n","                     [ 0,  0,  0],\n","                     [ 1,  2,  1]]\n","\n","plot_filter(images, horizontal_filter)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t8MkJJUvghZT"},"source":["By swapping the first and last rows of the above filter, we get a filter that detects horizontal lines from white on top to black underneath."]},{"cell_type":"code","metadata":{"id":"S3ORKLR5gjLo"},"source":["horizontal_filter = [[ 1,  2,  1],\n","                     [ 0,  0,  0],\n","                     [-1, -2, -1]]\n","\n","plot_filter(images, horizontal_filter)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iP_1cNU0gmnv"},"source":["We can also design filters that detect vertical lines. \n","\n","Here's one that detects vertical lines that are black on the left and white on the right."]},{"cell_type":"code","metadata":{"id":"U6RJwzjogm0U"},"source":["vertical_filter = [[-1, 0, 1],\n","                   [-2, 0, 2],\n","                   [-1, 0, 1]]\n","\n","plot_filter(images, vertical_filter)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OGU18dTJgtx2"},"source":["The great thing about convolutional layers is that each layer doesn't just have a single filter. It has as many filters as you want. Each filter has their own set of weights, so (in theory) is learning to extract different features. \n","\n","The image below shows what happens when we use a convolutional layer with five filters. The original image with a single color channel (as it's black and white) has five filters applied to it to get five filtered images. These images are then stacked together to get what we can think of as a single image with five channels.  \n","\n","![](https://github.com/bentrevett/pytorch-image-classification/blob/master/assets/multiple-filter-mnist.png?raw=1)\n","\n","What about when you now want to pass this five channel filtered image to another convolutional layer? Now, that convolutional layer won't just have a height and a width, but it will also have a depth equal to the number of channels in the input image.\n","\n","![](https://github.com/bentrevett/pytorch-image-classification/blob/master/assets/multiple-channel-mnist.png?raw=1)\n","\n","As you can see, the filter has a height, width and depth of 2x2x5. All of the 20 pixel values covered by this filter are multiplied by the filter's weight and then summed. The result of this will have as many channels as there are filters, and a subsequent convolutional layer will have to have filters with a depth equal to that number of channels.\n","\n","Hopefully that's enough on convolutional layers, but if not then there are [plenty](https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/) of [other](https://cs231n.github.io/convolutional-networks/) resources [about](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/) them [online](https://www.coursera.org/learn/convolutional-neural-networks).\n","\n","Next, we'll talk about the subsampling layers. These are layers used to reduce the size/resolution of their input and are commonly applied to the output of convolutional layers. The most common two methods of subsampling are *max pooling* and *mean pooling* (also known as *average pooling*), and thus subsampling is often know as *pooling*.\n","\n","Why do we want to reduce the resolution of the image? It speeds up our model, as convolution operations are expensive. If we subsample and half the size of our image before it passes into the next convolutional layer, that's a significant speed up.\n","\n","Subsampling layers aren't too different to convolutional layers. They have a filter with a size and a stride. However, pooling layers do not have any parameters - weights and biases. They simply perform an operation on the image. Max pooling returns the maximum of the values covered by the filter and we can think of it as extracting the single most important feature under the filter. Mean/average pooling returns the mean/average of the values covered by the filter and we can think of it as equally weighting all features under the filter.\n","\n","Let's look at a 2x2 pooling operation, with a stride of 2, over an image:\n","\n","![](https://github.com/bentrevett/pytorch-image-classification/blob/master/assets/subsample-mnist.png?raw=1)\n","\n","Commonly, and by default in PyTorch, the stride for the height and the width is the height and the width of the filter and each pixel is only seen by the pooling layer once, thus:\n","\n","$$\\text{height}_{\\text{out}} = \\frac{\\text{height}_\\text{in}}{\\text{filter}_{\\text{height}}}$$\n","\n","$$\\text{width}_{\\text{out}} = \\frac{\\text{width}_\\text{in}}{\\text{filter}_{\\text{width}}}$$\n","\n","For max pooling, the value of the output for each filter location is:\n","\n","![](https://github.com/bentrevett/pytorch-image-classification/blob/master/assets/single-pool.png?raw=1)\n","\n","Let's create a function that allows us to see the outputs of a pooling layer on a batch of images."]},{"cell_type":"code","metadata":{"id":"J0DZKxnPgt_Q"},"source":["def plot_subsample(images, pool_type, pool_size):\n","\n","    images = torch.cat([i.unsqueeze(0) for i in images], dim = 0).cpu()\n","    \n","    if pool_type.lower() == 'max':\n","        pool = F.max_pool2d\n","    elif pool_type.lower() in  ['mean', 'avg']:\n","        pool = F.avg_pool2d\n","    else:\n","        raise ValueError(f'pool_type must be either max or mean, got: {pool_type}')\n","    \n","    n_images = images.shape[0]\n","\n","    pooled_images = pool(images, kernel_size = pool_size)\n","\n","    fig = plt.figure(figsize = (20, 5))\n","    \n","    for i in range(n_images):\n","\n","        ax = fig.add_subplot(2, n_images, i+1)\n","        ax.imshow(images[i].squeeze(0), cmap='bone')\n","        ax.set_title('Original')\n","        ax.axis('off')\n","\n","        image = pooled_images[i].squeeze(0)\n","\n","        ax = fig.add_subplot(2, n_images, n_images+i+1)\n","        ax.imshow(image, cmap='bone')\n","        ax.set_title(f'Subsampled')\n","        ax.axis('off');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lbZrFb1AgyNl"},"source":["First, let's see max pooling with a filter size of 2. \n","\n","We can see that the image is heavily downsampled - reduced in size/resolution and in quality."]},{"cell_type":"code","metadata":{"id":"liuhhp17g087"},"source":["plot_subsample(images, 'max', 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5zcDF6Geg2Wp"},"source":["plot_subsample(images, 'max', 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ms-DsRUKg2o_"},"source":["plot_subsample(images, 'avg', 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtvFwcmog35p"},"source":["plot_subsample(images, 'avg', 3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SaS_Qh5Yg6cl"},"source":["### Define Model with nn.Module"]},{"cell_type":"markdown","metadata":{"id":"R3iG_C9-hBtJ"},"source":["![](https://github.com/bentrevett/pytorch-image-classification/blob/master/assets/lenet5.png?raw=1)"]},{"cell_type":"markdown","metadata":{"id":"6vzQtBT3hJoP"},"source":["The first layer in our model is convolutional layer with 6 filters (PyTorch calls them `out_channels`) and a kernel size of 5. This turns our `[1, 28, 28]` image into `[6, 24, 24]`. We then downsample our image with a max pooling layer that has a filter size of 2 to get a `[6, 12, 12]` image. This is then passed through an activation function, ReLU in this case, which is applied elementwise and does not change the of the image. \n","\n","Afterwards, we pass the image to the second convolutional layer with 16 filters that are 5x5x6, a height and width of 5 and a depth of 6 as our previous convolutional layer had 6 filters. This gives us an image size of `[16, 8, 8]` which we then max pool to half the heigth and width to `[16, 4, 4]` and then pass through another ReLU function.\n","\n","We then flatten our `[16, 4, 4]` image to `[256]` and pass this through three linear layers. Each of the linear layers are followed by another ReLU, except for the last.\n","\n","We return the results from the final linear layer as well as from the flattened result of the second convolutional layer, which we can plot in lower dimensions later.\n","\n","Note that you should always apply your activation function **after** the pooling layer. You will get the exact same results if you apply the activation function before, however this means you will be applying your activation function to a larger number of inputs, increasing the computation required. Using the activation function after the image has been reduced in size means it will be applied to less inputs and thus use less computation."]},{"cell_type":"markdown","metadata":{"id":"rOc8ktfuhLlj"},"source":["- Subsampling: forward 메소드 안에서 F.maxpool_2d 사용\n","- ReLU: forward 메소드 안에서 F.relu 사용\n","- 나머지 convolution / fc 들은 __init__ 메소드 안에 구현"]},{"cell_type":"code","metadata":{"id":"GtYwLb1Ig7mH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HopmtYQXiNU_"},"source":["모델 객체 선언"]},{"cell_type":"code","metadata":{"id":"IOCO0SBDiOuw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AsotR8-giPqD"},"source":["모델 파라미터 수 세기"]},{"cell_type":"code","metadata":{"id":"RQ0BHw3NiQgk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-w43jCpsiS7n"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"F3-sv6_giUTP"},"source":["- Optimizer\n","- Loss\n","- device 정의\n","- 모델, criterion device로 옮기기"]},{"cell_type":"code","metadata":{"id":"LzjSRLIiiTyJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uPjehBeOicfS"},"source":["Accuracy 계산 코드"]},{"cell_type":"code","metadata":{"id":"ig7f1K9IidU4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tT7cJo_6ifp4"},"source":["훈련 코드"]},{"cell_type":"code","metadata":{"id":"OD_uwbpOigay"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dnPSyRkSig2k"},"source":["평가 코드"]},{"cell_type":"code","metadata":{"id":"p_ksGRt9ih2q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e5pVSuwXijeR"},"source":["훈련할 epoch 수를 정의하고 training\n","- Validation acc가 증가할때마다 모델 save"]},{"cell_type":"code","metadata":{"id":"YQq8JEDXilvx"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KVX4JT4PirdT"},"source":["저장된 모델을 불러와 테스트 데이터셋에 대한 acc 측정"]},{"cell_type":"code","metadata":{"id":"J07mr8j3ivHa"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v2nS4_aJi55J"},"source":["## 모델 평가"]},{"cell_type":"markdown","metadata":{"id":"iYWeeasolCul"},"source":["테스트 데이터셋에 대해서 테스트 이미지, 라벨, 예측값을 리턴하는 함수 구성"]},{"cell_type":"code","metadata":{"id":"BKARcmrui6hX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GdJPIKN2lR0l"},"source":["torch.eq 메소드를 사용해 맞으면 True, 틀리면 False 를 담게 구현"]},{"cell_type":"code","metadata":{"id":"QXZy67NSlWuB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JjjA9AW_laFC"},"source":["틀린 이미지만 담아서 틀렸는데 확률이 가장 높은 이미지 순대로 sort\n","- 리스트에 담을때는 (image, label, pred) 튜플을 담음"]},{"cell_type":"code","metadata":{"id":"R79QvjkNldCT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mxjf4l3-lmjQ"},"source":["def plot_most_incorrect(incorrect, n_images):\n","\n","    rows = int(np.sqrt(n_images))\n","    cols = int(np.sqrt(n_images))\n","\n","    fig = plt.figure(figsize = (20, 10))\n","    for i in range(rows*cols):\n","        ax = fig.add_subplot(rows, cols, i+1)\n","        image, true_label, probs = incorrect[i]\n","        true_prob = probs[true_label]\n","        incorrect_prob, incorrect_label = torch.max(probs, dim = 0)\n","        ax.imshow(image.view(28, 28).cpu().numpy(), cmap = 'bone')\n","        ax.set_title(f'true label: {true_label} ({true_prob:.3f})\\n' \\\n","                     f'pred label: {incorrect_label} ({incorrect_prob:.3f})')\n","        ax.axis('off')\n","    fig.subplots_adjust(hspace=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lCdnQ-EWln4z"},"source":["N_IMAGES = 25\n","\n","plot_most_incorrect(incorrect_examples, N_IMAGES)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F-PbFMX5lwu3"},"source":["### Representation 분석"]},{"cell_type":"markdown","metadata":{"id":"Js72ULgYl48L"},"source":["테스트 데이터셋에 대해 (출력, convolution 마지막 출력, 라벨) 을 출력하는 함수를 구현"]},{"cell_type":"code","metadata":{"id":"7Nw9icgxlz67"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NlSCfmfymJel"},"source":["Plot 함수"]},{"cell_type":"code","metadata":{"id":"5laqzlQhmKHX"},"source":["def plot_representations(data, labels, n_images = None):\n","    if n_images is not None:\n","        data = data[:n_images]\n","        labels = labels[:n_images]\n","    fig = plt.figure(figsize = (10, 10))\n","    ax = fig.add_subplot(111)\n","    scatter = ax.scatter(data[:, 0], data[:, 1], c = labels, cmap = 'tab10')\n","    handles, labels = scatter.legend_elements()\n","    legend = ax.legend(handles = handles, labels = labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q3R0R-2KmMT1"},"source":["t-SNE 차원축소 결과를 출력하는 함수 구현"]},{"cell_type":"code","metadata":{"id":"nPlHOFs6mQZx"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zNwzAhbpmSbZ"},"source":["전체 중간 출력에 대해 plot "]},{"cell_type":"code","metadata":{"id":"KQrrU7yEmUHN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"czIGXqNlmUf_"},"source":["전체 최종 출력에 대해 plot"]},{"cell_type":"code","metadata":{"id":"E6w-UXr3mVcW"},"source":[""],"execution_count":null,"outputs":[]}]}